{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie domowe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 - eksploracja przestrzeni zagnieżdżeń\n",
    "Wczytajmy do przestrzeni plik zagnieżdżeń, który należy pobrać ze strony:\n",
    "https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pl.vec Są to zagnieżdzenia dla języka polskiego uzyskane systemem fastText.\n",
    "\n",
    "Do przestrzeni wczytujemy tylko 100 tys. najczęstrzych słów, tak aby operacje przebiegały szybciej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff72904e199199567cefa7ecc512bc5b",
     "grade": false,
     "grade_id": "cell-a4ed145fec4874e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def load_vectors(fname, limit = 100000):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    n = min(n,limit)\n",
    "    embeddings = np.empty((n,d), dtype = np.float)\n",
    "    words_idx = []\n",
    "    for i, line in enumerate(fin):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        words_idx.append(tokens[0])\n",
    "        embeddings[i] =  np.array(tokens[1:]).astype(np.float)\n",
    "    return words_idx, embeddings\n",
    "words_idx, embeddings = load_vectors('wiki.pl.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższe zadania mają na celu poekserymentowanie z przestrzenią zagnieżdżeń, ale też zrozumienie stojącymi za nich operacji. Dozwolone jest korzystanie tylko z podstawowych operatorów Python i numpy (w szczególności zakaz dotyczy: sklearn, gensim, fasttext itd.)\n",
    "\n",
    "Jeśli potrzebujesz do dalszego przetwarzania przeprowadzenia jakichś normalizacji macierzy -- możesz wstępnie przetworzyć macierz zagnieżdzeń poniżej. Pamiętaj, że sprawdzarka będzie używała wywołań do `embeddings` (i `words_idx`) -- musisz nadpisać macierz zagnieżdzeń. To pole jest pomocnicze i nie podlega ocenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bad4efac5cfe3b895e04c7d1d616878c",
     "grade": false,
     "grade_id": "cell-6fee4cb7a7fea5c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "d = {word:idx for idx,word in enumerate(words_idx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję, która obliczy podobieństwo kosinusowe pomiędzy dwoma wyrazami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89e46295053248c56d68caf5a00e3a81",
     "grade": false,
     "grade_id": "cell-433776f5de68cf95",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim(embed_a, embed_b):\n",
    "    return np.sum(embed_a * embed_b) / (np.sqrt(np.sum(embed_a**2))   *   np.sqrt(np.sum(embed_b**2)) )\n",
    "\n",
    "def calc_sim(word_a, word_b, words_idx, embeddings):\n",
    "    embed_a = embeddings[words_idx.index(word_a)]\n",
    "    embed_b = embeddings[words_idx.index(word_b)]\n",
    "#     embed_a = embeddings[d[word_a]]\n",
    "#     embed_b = embeddings[d[word_b]]\n",
    "    return cosine_sim(embed_a, embed_b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a0436c8372e1c2bc61b92bd05a6c765",
     "grade": true,
     "grade_id": "cell-890341bd1cbcc5d2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_almost_equal\n",
    "assert_almost_equal(calc_sim(\"bieber\", \"rihanna\", words_idx, embeddings), calc_sim(\"rihanna\", \"bieber\", words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policz podobieństwo pomiędzy wyrazem `bieber` a wyrazami:\n",
    "    - `rihanna`\n",
    "    - `piłsudski`\n",
    "    - `kanada`\n",
    "    - `polska`\n",
    "    - `piosenka`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.524583248263655"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_sim(\"bieber\", \"rihanna\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d0c5da4e71a95a4f3aacba9f9b4b664",
     "grade": false,
     "grade_id": "cell-3333712301dd0bbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.524583248263655,\n",
       " 0.19303958051463557,\n",
       " 0.20042742126487928,\n",
       " 0.12505934735679375,\n",
       " 0.2874871368858332]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "[calc_sim(\"bieber\", \"rihanna\", words_idx, embeddings),\n",
    "calc_sim(\"bieber\", \"piłsudski\", words_idx, embeddings),\n",
    "calc_sim(\"bieber\", \"kanada\", words_idx, embeddings),\n",
    "calc_sim(\"bieber\", \"polska\", words_idx, embeddings),\n",
    "calc_sim(\"bieber\", \"piosenka\", words_idx, embeddings)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcję, która zwróci najbardziej podobne słowa (miara kosinusowa) do danego słowa `word`. W wyniku wypisz tylko `top` słów z najbliższymi zagnieżdżeniami, pomijając słowo `word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d174e9429ec96be4232e58eb4683ffb8",
     "grade": false,
     "grade_id": "cell-e8417832104ee5eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_to_embedding(embed_word, words_idx, embedding_matrix, top):\n",
    "    idxs = np.argsort([cosine_sim(embed_word, embedding_matrix[i]) for i in range(np.shape(embedding_matrix)[0])])[-1-top:-1][::-1]\n",
    "    return np.array(words_idx)[idxs]\n",
    "        \n",
    "\n",
    "def find_similar(word, words_idx, embedding_matrix, top=10):\n",
    "    embed_word = embedding_matrix[words_idx.index(word)]\n",
    "    return find_similar_to_embedding(embed_word, words_idx, embedding_matrix, top)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff37028a810bf8da732cfdb41cc309b7",
     "grade": true,
     "grade_id": "cell-84f4627b3ebe0906",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(find_similar(\"radość\", words_idx, embeddings)) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znajdź najbardziej podobne słowa do kobieta, politechnika, mateusz, szczecin, niemcy, piłsudski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kobietą', 'dziewczyna', 'mężczyzna', 'kobietę', 'dziewczynka',\n",
       "       'mężczyznę', 'staruszka', 'mężczyzną', 'kobiecie', 'mężczyzny'],\n",
       "      dtype='<U31')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(\"kobieta\", words_idx, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f26fb5c5ebdbd5a5dd006c892c9aba",
     "grade": false,
     "grade_id": "cell-9e2eaa4a951e17b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['kobietą', 'dziewczyna', 'mężczyzna', 'kobietę', 'dziewczynka',\n",
       "        'mężczyznę', 'staruszka', 'mężczyzną', 'kobiecie', 'mężczyzny'],\n",
       "       dtype='<U31'),\n",
       " array(['politechniki', 'politechniką', 'politechnikę', 'politechniczny',\n",
       "        'politechnice', 'politechnicznej', 'politechnicznego',\n",
       "        'politechnicznym', 'inżynierska', 'elektrotechnika'], dtype='<U31'),\n",
       " array(['łukasz', 'bartłomiej', 'bartosz', 'kacper', 'marcin', 'mateusza',\n",
       "        'tomasz', 'patryk', 'rafał', 'mateuszem'], dtype='<U31'),\n",
       " array(['szczecinek', 'szczeciński', 'szczecinem', 'gryfino', 'szczecinie',\n",
       "        'stargard', 'szczecina', 'koszalin', 'szczecińska', 'świnoujście'],\n",
       "       dtype='<U31'),\n",
       " array(['niemieccy', 'naziści', 'alianci', 'okupanci', 'polacy',\n",
       "        'hitlerowcy', 'niemieckie', 'rosjanie', 'niemców', 'niemcom'],\n",
       "       dtype='<U31'),\n",
       " array(['piłsudskim', 'piłsudskiego', 'piłsudskiemu', 'sosnkowski',\n",
       "        'mościcki', 'śmigły', 'józef', 'żeligowski', 'piłsudczyków',\n",
       "        'sosnkowskiego'], dtype='<U31')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "[find_similar(\"kobieta\", words_idx, embeddings),\n",
    " find_similar(\"politechnika\", words_idx, embeddings),\n",
    " find_similar(\"mateusz\", words_idx, embeddings),\n",
    " find_similar(\"szczecin\", words_idx, embeddings),\n",
    " find_similar(\"niemcy\", words_idx, embeddings),\n",
    " find_similar(\"piłsudski\", words_idx, embeddings)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krótko skomentuj wyniki dla słowa `niemcy`. Które z powstałych analogii biorą się z semantycznego powiązania a które z semantycznego podobieństwa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c31c2929dc80543bebea431c05decbfd",
     "grade": true,
     "grade_id": "cell-f09fc185fd252182",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Semantyczne podobieństwo (jako przedstawiciele narodowości) - polacy, rosjanie.\n",
    "Semantyczne podobieństwo (jako nazwa przedstawiciele dowolnej grupy ludzi) - polacy, rosjanie, naziści, alianci, okupanci, hitlerowcy.\n",
    "\n",
    "Semantyczne powiązanie (poprzez państwo Niemcy) - niemieccy, niemieckie, niemców, niemcom.\n",
    "Semantyczne powiązanie (związane z II w.ś.) - naziści, alianci, okupanci, hitlerowcy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementuj funkcje szukającą brakującego elementu relacji ,,`word_a` jest do `word_a2` jak `word_b` jest do...''. Funkcja powinna zwrócić 10 najbardziej pasujących słow z pominięciem słów będących jej argumentami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e6e16dac4cb376f4d53a9d755cd46dc",
     "grade": false,
     "grade_id": "cell-63d29c3e720be966",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_pair(word_a, word_a2, word_b,  words_idx, matrix, top=10):\n",
    "    embed_a = matrix[words_idx.index(word_a)]\n",
    "    embed_a2 = matrix[words_idx.index(word_a2)]\n",
    "    embed_b = matrix[words_idx.index(word_b)]\n",
    "    \n",
    "    embed = embed_a2 - embed_a + embed_b\n",
    "    similar = find_similar_to_embedding(embed, words_idx, matrix, top+3)\n",
    "    return [w for w in similar if w not in [word_a, word_a2, word_b]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7663a43e711a8e860bbc06d41b6ca904",
     "grade": true,
     "grade_id": "cell-0d5187c215c3d03c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert find_similar_pair( \"mężczyzna\", \"król\", \"kobieta\", words_idx, embeddings)[0] == \"królowa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pieniądze są do profesora jak wiedza do..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96e68dff29fccbb7ee7cb889aeaaf45c",
     "grade": false,
     "grade_id": "cell-8f5621bb8ded7490",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['habilitowany',\n",
       " 'docent',\n",
       " 'wykładowca',\n",
       " 'profesorem',\n",
       " 'habilitacja',\n",
       " 'adiunkt',\n",
       " 'rektor',\n",
       " 'profesora',\n",
       " 'humanistycznych',\n",
       " 'naukowiec',\n",
       " 'prorektor',\n",
       " 'literaturoznawca']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "find_similar_pair( \"pieniądze\", \"profesor\", \"wiedza\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mateusza jest do mateusz jak łukasza do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89ccdc6a4c7685a211811f0c6d5e796e",
     "grade": false,
     "grade_id": "cell-3215c64840cc460e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['łukasz',\n",
       " 'bartłomiej',\n",
       " 'bartosz',\n",
       " 'maciej',\n",
       " 'tomasz',\n",
       " 'rafał',\n",
       " 'patryk',\n",
       " 'marcin',\n",
       " 'michał',\n",
       " 'przemysław',\n",
       " 'łukaszewski',\n",
       " 'bartczak']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "find_similar_pair( \"mateusza\", \"mateusz\", \"łukasza\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warszawa jest do \"polska\" jak \"berlin\" do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2831d8f28423fd701364d67e72570994",
     "grade": false,
     "grade_id": "cell-8e4d868c692f267a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['niemiecka',\n",
       " 'berliner',\n",
       " 'wschodnioniemiecka',\n",
       " 'berlińska',\n",
       " 'deutschland',\n",
       " 'deutsche',\n",
       " 'brandenburg',\n",
       " 'berlinem',\n",
       " 'germany',\n",
       " 'niemcy',\n",
       " 'berlinie',\n",
       " 'berlina']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "find_similar_pair( \"warszawa\", \"polska\", \"berlin\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zurich jest do ETH jak Poznań do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['„poznań',\n",
       " 'wrocław',\n",
       " 'poznania',\n",
       " 'poznańskie',\n",
       " 'uam',\n",
       " 'poznaniu',\n",
       " 'kraków',\n",
       " 'gniezno',\n",
       " 'poznańską',\n",
       " 'wlkp',\n",
       " 'wielkopolski',\n",
       " 'gorzów']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair( \"zurich\", \"eth\", \"poznań\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niemcy są do Merkel jak Polska do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaczyńska',\n",
       " 'lewandowska',\n",
       " 'kwaśniewska',\n",
       " 'ekonomistka',\n",
       " 'lekarka',\n",
       " 'parlamentarzystka',\n",
       " 'marcinkiewicz',\n",
       " 'olszewska',\n",
       " 'bezpartyjna',\n",
       " 'dziennikarka',\n",
       " 'nowacka',\n",
       " 'geremek']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_pair( \"niemcy\", \"merkel\", \"polska\", words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na wektorach możemy wykonywać standardowe operacje algebry liniowej takie jak np. projekcja czyli rzutowanie danych na jakichś zbiór osi (więcej: notatki z algebry liniowej np. https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/least-squares-determinants-and-eigenvalues/projections-onto-subspaces/). W szczególności może to się przydać do zrzutowania słowa na przestrzeń w której pewny wybrany kierunek (wskazywany przez wektor) jest eliminowany.\n",
    "\n",
    "Do czego może to się przydać? Jeśli uruchomisz funkcję `find_similar` dla słowa ,,mateusza'' znajdziesz m.in. ,,łukasza'' ale także ,,ewangelia'', ,,ewangelisty'' i ,,apostoła''. Chcąc pominąc kontekst religijny tego słowa możesz zrzutować jego reprezentacje na przestrzeń bez wektora ,,ewangelia'' i poszukać jego najbliższych sąsiadów (którymi będą teraz po prostu imiona męskie). Zaimplementuj taką funkcję.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c635c05e6782ad6ef07a5ac3346f65c9",
     "grade": false,
     "grade_id": "cell-9c73750e7d423c6a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardowe poszukiwanie: ['łukasza' 'ewangelii' 'ewangelisty' 'ewangelia' 'bartłomieja'\n",
      " 'ewangeliach' 'apostoła' 'mateusz' 'tymoteusza' 'jakuba']\n",
      "Poszukiwanie po projekcji: ['łukasza' 'macieja' 'bartłomieja' 'marcina' 'piotra' 'andrzeja' 'mateusz'\n",
      " 'jakuba' 'tomasza' 'michała']\n"
     ]
    }
   ],
   "source": [
    "#https://en.wikipedia.org/wiki/Orthogonal_complement\n",
    "def get_orthogonal_complement_full_matrix(vectors):\n",
    "\n",
    "    def zeroOutDimension(vectorZeroed, vectorZeroing, zeroingInd):\n",
    "        vectorZeroed -= vectorZeroing * vectorZeroed[zeroingInd] / vectorZeroing[zeroingInd]\n",
    "\n",
    "    def normalizeDimension(vectorNormalized, normalizedInd):\n",
    "        vectorNormalized /= vectorNormalized[normalizedInd]\n",
    "\n",
    "    for zeroingInd, vectorZeroing in enumerate(vectors):\n",
    "        for zeroedInd, vectorZeroed in enumerate(vectors):\n",
    "            if zeroingInd!=zeroedInd:\n",
    "                zeroOutDimension(vectorZeroed, vectorZeroing, zeroingInd)\n",
    "\n",
    "    for normalizedInd, vectorNormalized in enumerate(vectors):\n",
    "        normalizeDimension(vectorNormalized, normalizedInd)\n",
    "\n",
    "    matrix = np.identity(np.shape(vectors)[1])\n",
    "    matrix[:, :np.shape(vectors)[0]] = np.transpose(-vectors)\n",
    "    matrix[:np.shape(vectors)[0]] = vectors\n",
    "\n",
    "\n",
    "    return matrix.T\n",
    "\n",
    "def transform_vector_space(vector_space, transformation_matrix):\n",
    "    return (np.linalg.inv(transformation_matrix) @ vector_space.T).T\n",
    "\n",
    "def find_similar_with_rejection(word, remove, words_idx, matrix, top=10):\n",
    "    \"\"\"\n",
    "    Działanie analogiczne do find_similar z dodatkowym parametrem remove, \n",
    "    który jest *listą* słów, które należy wyrzucić poprzez projekcję.\n",
    "    Dla remove=[] powinno się zwracać dokładnie to samo co find_similar\n",
    "    \"\"\"\n",
    "    if len(remove)>0:\n",
    "        words_removed = np.array([embeddings[words_idx.index(wordR)] for wordR in remove])\n",
    "        # setting vectors to remove as first k basis vectors of transformed space\n",
    "        transformation_matrix = get_orthogonal_complement_full_matrix(words_removed)\n",
    "        matrix_transformed = transform_vector_space(matrix, transformation_matrix)\n",
    "\n",
    "        matrix_transformed = matrix_transformed[:, np.shape(words_removed)[0]:] # dropping vector dimension\n",
    "    else:\n",
    "        matrix_transformed = matrix\n",
    "    \n",
    "    return find_similar(word, words_idx, matrix_transformed, top)\n",
    "    \n",
    "    \n",
    "print (\"Standardowe poszukiwanie:\", find_similar_with_rejection(\"mateusza\",[] , words_idx, embeddings))\n",
    "print (\"Poszukiwanie po projekcji:\", find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings))\n",
    "\n",
    "\n",
    "## Zaimplementowana metoda przekształca całą przestrzeń zagnieżdżeń: vector_space = matrix\n",
    "## macierzą transformacji o nowych współrzędnych n osi wybranych jako:\n",
    "## k -> pierwszych osi -> kierunki, które mamy usunąć\n",
    "## n-k -> pozostałych osi -> osie wyznaczone w taki sposób, aby tworzyły n-k wymiarową przestrzeń prostopadłą do k wymiarowej\n",
    "## przestrzeni pierwszych osi\n",
    "\n",
    "## Po transformacji k pierwszych kolumn w embeddingsach oznacza jak bardzo słowo jest podobne do słowa, którego embedding\n",
    "## przyjęliśmy na tę oś, a embedding usuniętego słowa dla \"własnej osi\" ma wartość 1, dla pozostałych osi wartość 0.\n",
    "\n",
    "## Następnie usuwamy k pierwszych kolumn/osi usuwając z przestrzeni te kierunki - posiadając n-k wymiarową\n",
    "## przestrzeń prostopadłą do usuniętej przestrzeni k wymiarowej - tzn. punkty w usuniętej przestrzeni są niedostępne\n",
    "## dla przestrzeni pozostałej tzn. ze wszystkich embeddingsów słów usunęliśmy całkowicie podobieństwo (wg. embeddingsów) \n",
    "## do usuniętych słów. \n",
    "\n",
    "## Operacja jest dość kosztowna bo wymaga przekształcenia całej macierzy embeddingsów\n",
    "## oprócz tego tracimy k wymiarów embeddingsów - jest ograniczona liczba słów, którą możemy w taki sposób usunąć. \n",
    "\n",
    "## W związku z inną niż proponowana przez prowadzącego implementacja - słowa zwrócone zastosowaną metodą\n",
    "## mogą zwracać inne słowa niż zakładane i nie przejść ukrytych testów - proszę o nie branie takich ewentualnych ukrytych testów\n",
    "## pod uwagę w ocenianiu :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cf5c44bd1df54c1da4106b8830dd322",
     "grade": true,
     "grade_id": "cell-b647aedbe8f9db7b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"ewangelii\" in find_similar_with_rejection(\"mateusza\",[] , words_idx, embeddings)\n",
    "assert \"ewangelii\" not in find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings)\n",
    "assert \"ewangelisty\" not in find_similar_with_rejection(\"mateusza\",[\"ewangelia\"] , words_idx, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogicznie słowo ,,java'' jest nie tylko nazwą języka programownia (https://pl.wikipedia.org/wiki/Java_(ujednoznacznienie)) -- jest np. nazwą geograficzną (indonezyjska wyspa koło Sumatry). Sprawdź jakie wyrazy są podobne do \"java\" oraz po odrzuceniu kierunku \"javascript\" (tj. kierunku związanego z językami programowania)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e732ddade5feede63d07547766bcf949",
     "grade": false,
     "grade_id": "cell-d9d015bfeb8e25f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['javy', 'sumatra', 'krążowniki', 'indonezja', 'c#', 'tromp', 'api',\n",
       "       'niszczycielami', 'obiektowe', 'penang'], dtype='<U31')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_with_rejection(\"java\",[\"javascript\"] , words_idx, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbuj poekseprymentować samemu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a88f0a6d0571a66b40d04bc9cb8e65a",
     "grade": false,
     "grade_id": "cell-673e06a42de6bc26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sumatra' 'javy' 'penang' 'indonezja' 'niszczycielami' 'hmas'\n",
      " 'krążowniki' 'jawa' 'tromp' 'emden']\n",
      "['sumatra' 'niszczycielami' 'hmas' 'indonezja' 'javy' 'tromp' 'krążowniki'\n",
      " 'flagowy' 'niszczyciele' 'jawa']\n",
      "['kelnerka' 'sekretarka' 'policjantka' 'recepcjonistka' 'pielęgniarka'\n",
      " 'asystentka' 'kucharka' 'prostytutka' 'kierowniczka' 'pracownica']\n",
      "['sprzątanie' 'sprzątania' 'sekretarka' 'recepcjonistka' 'kelnerka'\n",
      " 'kierowniczka' 'pielęgniarka' 'asystentka' 'nauczycielka' 'dyrektorka']\n"
     ]
    }
   ],
   "source": [
    "# usuwając dodatkowo kierunek \"programowanie\" - pozbywamy się dodatkowo informacji o c#, api i obiektowe (pewnie programowanie)\n",
    "# wygląda na to, że informacja o programowaniu była reprezentowana przez więcej aspektów niż te ukryte jedynie w \"javascript\"\n",
    "print(find_similar_with_rejection(\"java\",[\"javascript\", \"programowanie\"] , words_idx, embeddings))\n",
    "\n",
    "\n",
    "# podobny efekt uzyskujemy dla c# -> również tracimy api i obiektowe (wygląda na to, że c# jako język backendowy kojarzony\n",
    "# jest bardziej z api (niż javascript?) oraz jest językiem bardziej kojarzonym z paradygmatem obiektowym)\n",
    "print(find_similar_with_rejection(\"java\",[\"javascript\", \"c#\"] , words_idx, embeddings))\n",
    "\n",
    "# dzięki usunięciu widocznych poniżej osi, najbliższe wyrazy stały się niezależne od płci \n",
    "# (pomimo podania słowa odmienionego przez płeć)\n",
    "print(find_similar_with_rejection(\"sprzątaczka\",[] , words_idx, embeddings))\n",
    "\n",
    "print(find_similar_with_rejection(\"sprzątaczka\",[\"kobieta\", \"mężczyzna\", \"ona\", \"on\"] , words_idx, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykonanie projekcji w przestrzeni zagnieżdżeń może być jedną z prostych technik zwalczenia tzw. gender bias (http://wordbias.umiacs.umd.edu/) w reprezentacji słów. Okazuje się, że wykonanie projekcji macierzy zagnieżdżeń na przestrzeń w której ,,brakuje kierunku he-she'' może być bardzo prostą techniką zredukowania tego typu obciążenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 - zagnieżdżenia dokumentów\n",
    "W tym ćwiczeniu powócimy do zbioru tweetów, który analizowaliśmy w poprzednim dokumencie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data set ['tweets.txt']\n"
     ]
    }
   ],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear @Microsoft the newOoffice for Mac is great and all, but no Lync update? C'mon.\n",
      "['dear', '@microsoft', 'the', 'newooffice', 'for', 'mac', 'is', 'great', 'and', 'all', ',', 'but', 'no', 'lync', 'update', '?', \"c'mon\", '.']\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem do zbudowania reprezentacji będziemy używać narzędzie Universal Sentence Encoder stworzone przez Googla na bazie głębokiej sieci uśredniającej (i architektur rekurencyjnych). Poniższy kod pokazuje sposób użycia tego narzędzia. \n",
    "Kod spokojnie można wywoływać na CPU -- choć ściąganie modelu trochę może potrwać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03133017 -0.06338635 -0.01607501 ... -0.0324278  -0.04575742\n",
      "   0.05370458]\n",
      " [ 0.05080862 -0.01652429  0.01573782 ...  0.0097666   0.03170121\n",
      "   0.01788118]], shape=(2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"])\n",
    "print (embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując reprezetnację USE wytrenuj wybrany klasyfikator z pakietu `sklearn` i zweryfikuj jego jakość działania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ec9460c36ab328559c89319de53da65",
     "grade": false,
     "grade_id": "cell-26c33314c55313ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest, accuracy: 0.6009988901220865\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# tensorflow 2.0.0 or newer\n",
    "X = embed([tweet.text for tweet in training_set.tweets]).numpy()\n",
    "\n",
    "y = [i.clazz for i in training_set.tweets]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf  = RandomForestClassifier(n_estimators=20, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(\"Random Forest, accuracy: \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skomentuj wyniki i odnieś je do wyników z poprzedniego zadania domowego. Na ile użycie reprezentacji rozproszonych pozwoliło na poprawę wyników?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "635819ecfcec9e909b5f4b2261ea14a5",
     "grade": true,
     "grade_id": "cell-e08f7b8feff88383",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Użycie reprezentacji rozproszonych zwiększyło trafność klasyfikacji Random Forest (w tej samej konfiguracji) z 0.568\n",
    "(dla klastrów browna), i z 0.580 (najlepsza konfiguracja hashowania) do 0.600. Jest to poprawa o odpowiednio, o około 5.5% oraz 3.5% trafności - wydaje się to dość znacząca poprawa, szczególnie, że zastosowany model nie jest wyrafinowany - możliwe, że mocniejszy model potrafiłby uzyskać jeszcze większe polepszenie wyników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 3 - konstruowanie zagnieżdżeń\n",
    "W tym ćwiczeniu kontynuujemy pracę z tweetami, ale pomijamy całkowicie ich klasy. Zbiór tweetów potraktujemy jako korpus do nauczenia zagnieżdżeń słów przy pomocy macierzy PMI.\n",
    "- Wypełnij macierz kontekst - dokument przy użyciu symetrycznego okna o promieniu 4 (po 4 słowa w każdą stronę)\n",
    "- Możesz ograniczyć słownictwo do 10K słów\n",
    "- Przekształć macierz w macierz PPMI\n",
    "- Stwórz zagnieżdżenia wykorzystując dekompozycję SVD do wybranej wymiarowości $d$ (ze względu na koszt obliczeniowy może to być mała wymiarowość np. $d=10$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d780996410f05351b8dc57e50531c78d",
     "grade": true,
     "grade_id": "cell-dc2433e668962e28",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\piotr\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:66: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of word: the = [-0.13393392  0.17933441 -0.36174603  0.01115794  0.36489091 -0.33519542\n",
      " -0.11976622 -0.30472809 -0.59883297 -0.32804078]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.13393392,  0.17933441, -0.36174603, ..., -0.30472809,\n",
       "        -0.59883297, -0.32804078],\n",
       "       [-0.35739485, -0.08010197, -0.40097614, ..., -0.00842042,\n",
       "        -0.61931274, -0.31606749],\n",
       "       [-0.18342168, -0.19327841, -0.23983594, ..., -0.32607908,\n",
       "        -0.63501306, -0.34592036],\n",
       "       ...,\n",
       "       [-0.16671406, -0.30649568, -0.4776308 , ...,  0.04280096,\n",
       "         0.42409233, -0.21069002],\n",
       "       [-0.12806573, -0.25234931,  0.07536458, ...,  0.60488771,\n",
       "         0.53215151, -0.29560054],\n",
       "       [-0.20225923, -0.18782181,  0.33274312, ...,  0.59123672,\n",
       "         0.43065011, -0.29270055]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach inspired by \n",
    "# https://www.kaggle.com/gabrielaltay/word-vectors-from-pmi-matrix?fbclid=IwAR38v32cjpDzJZAdJBTsloAVYspANhk2Xn1CYbzX0ByhscCvR0gDKYIEUIk\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "vocab_size = 10000\n",
    "word_ctr = Counter()\n",
    "\n",
    "\n",
    "def count_words(tweet, ctr):\n",
    "    for word in tweet.tokens:\n",
    "        ctr[word] += 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "for tweet in training_set.tweets:\n",
    "    count_words(tweet, word_ctr)\n",
    "    \n",
    "\n",
    "token_to_ind = {}\n",
    "ind_to_token = {}\n",
    "# create dictionaries that convert tokens to indices and reverse\n",
    "for ind, (word, count) in enumerate(word_ctr.most_common(vocab_size)):\n",
    "   \n",
    "    token_to_ind[word] = ind\n",
    "    ind_to_token[ind] = word\n",
    "    \n",
    "\n",
    "#print(token_to_ind.keys())\n",
    "    \n",
    "fram_size_by_side = 4\n",
    "co_occurences_ctr = Counter()\n",
    "\n",
    "\n",
    "def count_co_occurences(tweet, co_occurences_ctr, token_to_ind):\n",
    "    \n",
    "    for ind, word in enumerate(tweet.tokens):\n",
    "        \n",
    "        if word not in token_to_ind:\n",
    "            continue\n",
    "        for context_pos in range(max(0, ind-fram_size_by_side), min(len(tweet.tokens), ind+fram_size_by_side+1)):\n",
    "            # check if we hit actual word, not context\n",
    "            if context_pos != ind and tweet.tokens[context_pos] in token_to_ind:\n",
    "                #print((token_to_ind[word], token_to_ind[tweet.tokens[context_pos]]))\n",
    "                co_occurences_ctr[(token_to_ind[word], token_to_ind[tweet.tokens[context_pos]])] +=1\n",
    "\n",
    "\n",
    "for tweet in training_set.tweets:\n",
    "    count_co_occurences(tweet, co_occurences_ctr, token_to_ind)\n",
    "\n",
    "#print([(ind_to_token[w], ind_to_token[c]) for ((w, c), cnt) in co_occurences_ctr.most_common(10)])\n",
    "\n",
    "\n",
    "\n",
    "word_context = np.zeros((vocab_size,vocab_size))\n",
    "rows, cols = zip(*co_occurences_ctr.keys())\n",
    "values = list(co_occurences_ctr.values())\n",
    "\n",
    "\n",
    "\n",
    "np.add.at(word_context, (rows,cols), values)\n",
    "\n",
    "log_word_context = np.log(word_context)\n",
    "\n",
    "\n",
    "log_sum_over_words = np.log(np.sum(word_context, axis=0))\n",
    "log_sum_over_contexts = np.log(np.sum(word_context, axis=1))\n",
    "\n",
    "\n",
    "log_sum = np.log(np.sum(word_context))\n",
    "\n",
    "pmi = ((log_word_context + log_sum - log_sum_over_words).transpose() - log_sum_over_contexts).transpose()\n",
    "\n",
    "ppmi = np.where( pmi >0, pmi, 0) \n",
    "\n",
    "u,s, vt = svds(ppmi, 10)\n",
    "\n",
    "#print(u.shape)\n",
    "u_norm = (u.T/np.linalg.norm(u, ord=2, axis=1)).T\n",
    "\n",
    "\n",
    "#print(np.sqrt(np.sum(u_norm**2, axis=1)))\n",
    "\n",
    "print(\"Embedding of word: \" + ind_to_token[0] + \" = \" + str(u_norm[0]))\n",
    "\n",
    "new_words_idx = list(ind_to_token.values())\n",
    "\n",
    "u_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestuj działanie Twoich zagnieżdżeń wykorzystując funkcję `find_similar` na wybranych słowach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccb11abbddd43b64c364aea20584f1dd",
     "grade": true,
     "grade_id": "cell-f6fa13a67093698a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['referee' 'mascot' 'attending' 'england' 'showed' 'harvey' 'football'\n",
      " 'khan' 'keeps' 'expressed']\n",
      "['v' '12th' 'la' 'league' 'everton' 'liverpool' 'premier' 'defender'\n",
      " 'champions' '@katetscott']\n",
      "['potter' 'off' 'hannibal' 'got' 'jurassic' 'had' 'watching' 'good'\n",
      " 'world' 'thrones']\n"
     ]
    }
   ],
   "source": [
    "# zagnieżdżenia wydają się dużo słabsze (aczkolwiek też sensowne), ale z drugiej strony mamy tutaj tylko 10000 słów \n",
    "# (i zagnieżdżenia też na 10000 są zbudowane)\n",
    "print(find_similar('soccer', new_words_idx, u_norm))\n",
    "\n",
    "print(find_similar('football', new_words_idx, u_norm))\n",
    "\n",
    "\n",
    "print(find_similar('harry', new_words_idx, u_norm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
